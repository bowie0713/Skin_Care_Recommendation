---
title: "skincare"
author: "Christina Pham"
date: "2025-01-30"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(httr)
library(rvest)
library(jsonlite)
library(tidyverse)
library(reticulate)
library(dplyr)
library(stringr)
```

```{python}
import requests
from bs4 import BeautifulSoup
import pandas as pd

# Step 1: Extract all product URLs from the sitemap
sitemap_url = "https://www.sephora.com/sitemaps/products-sitemap_en-CA.xml"

```

```{python}
from selenium import webdriver
import time

# Initialize Selenium WebDriver
options = webdriver.ChromeOptions()
options.add_argument("--disable-gpu")
driver = webdriver.Chrome(options = options)  # Ensure you have ChromeDriver installed
driver.get(sitemap_url)

time.sleep(5)

# Get the page source after fully loading
sitemap_html = driver.page_source

driver.quit()
```

```{r}
#save sitemap
sitemap_html <- py$sitemap_html
writeLines(sitemap_html, "sitemap.html")

# TO DO: 
#Check for unavailable prods 
# <h1 class="css-tz2kl4 e15t7owz0" data-comp="BaseComponent ">Sorry, this product is not available.</h1>

```

```{python}
soup = BeautifulSoup(sitemap_html, 'html.parser')
#soup
rows = soup.select('loc')
#rows
rows = pd.DataFrame(rows)
```

```{r}
library(stringr)
rows_html <- py$rows
colnames(rows_html) <- c("link")

categorized_links <- list()

categories <- list(
  shampoo = c("shampoo"),
  conditioner = c("conditioner"),
  cleanser = c("cleanser", "cleanse", "cleansing"),
  cream = c("cream", "creme", "moisturizer"),
  toner = c("toner"),
  serum = c("serum", "essence"),
  mask = c("mask")
)

for (category in names(categories)) {
  # Get the keywords for the current category
  keywords <- categories[[category]]
  
  # Create a filter condition for the keywords
  condition <- paste0("str_detect(link, '", keywords, "')", collapse = " | ")
  
 "
]}
```

rows_html %>% 
  filter(
    str_detect(link, "shampoo") | str_detect(link, "conditioner") | str_detect(link, "cleanser") | str_detect(link, "cleanse") | str_detect(0, "cleansing") | str_detect(link, "cream") | str_detect(link, "creme") | str_detect(link, "moisturizer") | str_detect(0, "toner") | str_detect(link, "serum") | str_detect(link, "mask") | str_detect(link, "essence")
  )

```{r}
# Access rows from Python
rows_html <- py$rows

# Set column name
colnames(rows_html) <- "link"

# Define categories and their associated keywords
categories <- list(
  shampoo = c("shampoo"), 
  conditioner = c("conditioner"),
  cleanser = c("cleanser", "cleanse", "cleansing"),
  cream = c("cream","creme","moisturizer"),
  toner = c("toner"),
  serum = c("serum", "essence"),
  mask = c("mask")
)
categorized_links <- list()

for (category in names(categories)) {
  keywords <- categories[[category]]
    filtered_links <- rows_html %>% 
    filter(
      sapply(keywords, function(keyword) str_detect(link, keyword)) %>% 
        rowSums() > 0
    )
    categorized_links[[category]] <- filtered_links
}

categorized_links

```

